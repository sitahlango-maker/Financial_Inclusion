{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/sitahlango-maker/Financial_Inclusion/blob/main/Colab%20Notebooks/Copy%20of%20FinancialInclusion.ipynb",
      "authorship_tag": "ABX9TyOzgmekquTEDZ0zZhOFcp9R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sitahlango-maker/Financial_Inclusion/blob/main/Colab%20Notebooks/Copy%20of%20FinancialInclusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Basic Liberaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Imports the pandas library for data handling and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Loads the Kenya survey data file from the public GitHub repository.\n",
        "df_ken = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/main/Colab%20Notebooks/FinancialInclution/Findex_Microdata_2025_Kenya.csv')\n",
        "\n",
        "# Loads the Tanzania survey data file from the public GitHub repository.\n",
        "df_tza = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/main/Colab%20Notebooks/FinancialInclution/Findex_Microdata_2025_Tanzania.csv')\n",
        "\n",
        "# Loads the Uganda survey data file from the public GitHub repository.\n",
        "df_uga = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/main/Colab%20Notebooks/FinancialInclution/Findex_Microdata_2025_Uganda.csv')\n",
        "\n",
        "# Prints the number of rows and columns for each countryâ€™s survey file to confirm successful loading.\n",
        "print(\"Kenya shape:\", df_ken.shape)\n",
        "print(\"Tanzania shape:\", df_tza.shape)\n",
        "print(\"Uganda shape:\", df_uga.shape)\n",
        "\n",
        "# Shows the first 15 column names of the Kenya file to check the structure.\n",
        "print(\"\\nKenya columns:\", df_ken.columns.tolist()[:15], \"...\")"
      ],
      "metadata": {
        "id": "I3oFpIt2b-nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887f1539-7eb8-495c-b18e-76e5d43759d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kenya shape: (1000, 183)\n",
            "Tanzania shape: (1000, 183)\n",
            "Uganda shape: (1000, 183)\n",
            "\n",
            "Kenya columns: ['year', 'economy', 'economycode', 'regionwb', 'pop_adult', 'wpid_random', 'wgt', 'female', 'age', 'educ', 'inc_q', 'emp_in', 'urbanicity', 'account_fin', 'account_mob'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning** **initial** **Findex** **Dataset**"
      ],
      "metadata": {
        "id": "omMU52Brkc1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines function to clean one survey file from any country.\n",
        "def clean_findex(df, country_code, country_name):\n",
        "\n",
        "    # Makes copy of data so original file remains unchanged.\n",
        "    df = df.copy()\n",
        "\n",
        "    # Adds full country name as new column.\n",
        "    df['country'] = country_name\n",
        "\n",
        "    # Adds short country code (KEN, TZA, UGA) as new column.\n",
        "    df['country_code'] = country_code\n",
        "\n",
        "    # Checks if weight column exists and changes it to numbers.\n",
        "    if 'wgt' in df.columns:\n",
        "        df['wgt'] = pd.to_numeric(df['wgt'], errors='coerce')\n",
        "\n",
        "    # Lists three main columns that show mobile money use.\n",
        "    target_cols = ['account_mob', 'dig_account', 'anydigpayment']\n",
        "\n",
        "    # Changes each main column to numbers if it exists.\n",
        "    for col in target_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Lists most useful columns to keep after cleaning.\n",
        "    keep = ['country', 'country_code', 'wgt', 'female', 'age', 'educ', 'inc_q',\n",
        "            'urbanicity', 'account_mob', 'dig_account', 'anydigpayment', 'internet_use']\n",
        "\n",
        "    # Removes any listed columns that do not exist in file.\n",
        "    keep = [c for c in keep if c in df.columns]\n",
        "\n",
        "    # Keeps only selected columns and removes all others.\n",
        "    df = df[keep]\n",
        "\n",
        "    # Returns cleaned file.\n",
        "    return df"
      ],
      "metadata": {
        "id": "5VJpZvdswjFx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying Cleaning and applying survey data**"
      ],
      "metadata": {
        "id": "ELVnlKhcwu1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleans Kenya survey data using the cleaning function.\n",
        "df_ken_clean = clean_findex(df_ken, 'KEN', 'Kenya')\n",
        "\n",
        "# Cleans Tanzania survey data using the cleaning function.\n",
        "df_tza_clean = clean_findex(df_tza, 'TZA', 'Tanzania')\n",
        "\n",
        "# Cleans Uganda survey data using the cleaning function.\n",
        "df_uga_clean = clean_findex(df_uga, 'UGA', 'Uganda')\n",
        "\n",
        "# Combines three cleaned files into one single table.\n",
        "df_micro = pd.concat([df_ken_clean, df_tza_clean, df_uga_clean], ignore_index=True)\n",
        "\n",
        "# Prints total rows and columns of combined table.\n",
        "print(\"Combined microdata shape:\", df_micro.shape)\n",
        "\n",
        "# Shows how many rows belong to each country.\n",
        "print(df_micro['country'].value_counts())\n",
        "\n",
        "# Prints percentage of missing values in each column (top 12).\n",
        "print(\"\\nMissing values (%):\\n\", df_micro.isna().mean().sort_values(ascending=False).head(12))"
      ],
      "metadata": {
        "id": "YTie8SmEwo-G",
        "outputId": "894ed6f9-0401-44ea-ef59-fc2628c193ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined microdata shape: (3000, 12)\n",
            "country\n",
            "Kenya       1000\n",
            "Tanzania    1000\n",
            "Uganda      1000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Missing values (%):\n",
            " educ             0.001\n",
            "country          0.000\n",
            "wgt              0.000\n",
            "country_code     0.000\n",
            "female           0.000\n",
            "age              0.000\n",
            "inc_q            0.000\n",
            "urbanicity       0.000\n",
            "account_mob      0.000\n",
            "dig_account      0.000\n",
            "anydigpayment    0.000\n",
            "internet_use     0.000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the country level dataset**"
      ],
      "metadata": {
        "id": "ZVR1CyXtxFG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads prevalence index file .\n",
        "df_preval = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/refs/heads/main/Colab%20Notebooks/FinancialInclution/Mobile%20Money%20Prevalent%20Index-2020-23-Public(MMPI%202020-23).csv')\n",
        "\n",
        "# Keeps only needed columns and removes rows without valid code.\n",
        "df_preval = df_preval[['Country', 'ISO3', 'Mobile Money Prevalence (2023)']].dropna(subset=['ISO3'])\n",
        "\n",
        "# Changes column names to be short and clear.\n",
        "df_preval.columns = ['country_name', 'country_code', 'mmpi_2023']\n",
        "\n",
        "# Keeps only Kenya, Tanzania, and Uganda rows.\n",
        "df_preval = df_preval[df_preval['country_code'].isin(['KEN', 'TZA', 'UGA'])]"
      ],
      "metadata": {
        "id": "jOm8TX53xL-K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads regulatory index file\n",
        "df_reg = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/main/Colab%20Notebooks/FinancialInclution/Mobile_Money_Regulatory_Index_Database_2025_v2(Data).csv')\n",
        "\n",
        "# Keeps only rows from year 2025 (latest data).\n",
        "df_reg = df_reg[df_reg['Year'] == 2025]\n",
        "\n",
        "# Keeps only selected columns that are most relevant.\n",
        "df_reg = df_reg[['Country', 'Index', 'Consumer Protection', 'KYC Proportionality',\n",
        "                 'Entry-level transaction limits', 'Maximum transaction limits', 'Agent Eligibility']]\n",
        "\n",
        "# Changes column names to be short and clear.\n",
        "df_reg.columns = ['country_name', 'reg_index', 'reg_cons_prot', 'reg_kyc_prop',\n",
        "                  'reg_entry_lim', 'reg_max_lim', 'reg_agent_el']\n",
        "\n",
        "# Adds short country code using country name.\n",
        "df_reg['country_code'] = df_reg['country_name'].map({'Kenya': 'KEN', 'Tanzania': 'TZA', 'Uganda': 'UGA'})\n",
        "\n",
        "# Keeps only Kenya, Tanzania, and Uganda rows.\n",
        "df_reg = df_reg[df_reg['country_code'].isin(['KEN', 'TZA', 'UGA'])]"
      ],
      "metadata": {
        "id": "mzq0383Yx76H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads deployment tracker file\n",
        "df_deploy = pd.read_csv('https://raw.githubusercontent.com/sitahlango-maker/Financial_Inclusion/refs/heads/main/Colab%20Notebooks/FinancialInclution/Mobile%20Money%20Deployment.csv')\n",
        "\n",
        "# Keeps only rows for Kenya, Tanzania, and Uganda.\n",
        "df_deploy = df_deploy[df_deploy['Country ISO Code'].isin(['KEN', 'TZA', 'UGA'])]\n",
        "\n",
        "# Counts number of mobile money providers per country.\n",
        "df_providers = df_deploy.groupby('Country ISO Code').size().reset_index(name='num_providers')\n",
        "\n",
        "# Changes country code column name to match others.\n",
        "df_providers = df_providers.rename(columns={'Country ISO Code': 'country_code'})\n",
        "\n",
        "# Changes launch year to numbers (ignores errors).\n",
        "df_deploy['launch_year'] = pd.to_numeric(df_deploy['Launch Year'], errors='coerce')\n",
        "\n",
        "# Finds earliest launch year per country.\n",
        "df_oldest = df_deploy.groupby('Country ISO Code')['launch_year'].min().reset_index(name='earliest_launch_year')\n",
        "\n",
        "# Changes country code column name to match others.\n",
        "df_oldest = df_oldest.rename(columns={'Country ISO Code': 'country_code'})"
      ],
      "metadata": {
        "id": "15CsIq3zyMY-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Country Facts Table**"
      ],
      "metadata": {
        "id": "JoqBKQaYzhSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Starts country facts table with prevalence category.\n",
        "df_country_facts = df_preval[['country_code', 'mmpi_2023']].copy()\n",
        "\n",
        "# Adds regulatory scores using left join.\n",
        "df_country_facts = df_country_facts.merge(\n",
        "    df_reg[['country_code', 'reg_index', 'reg_cons_prot', 'reg_kyc_prop',\n",
        "            'reg_entry_lim', 'reg_max_lim', 'reg_agent_el']],\n",
        "    on='country_code',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Combines provider count and earliest launch year.\n",
        "df_deploy_info = df_providers.merge(df_oldest, on='country_code', how='left')\n",
        "\n",
        "# Adds provider information to country facts table.\n",
        "df_country_facts = df_country_facts.merge(df_deploy_info, on='country_code', how='left')\n",
        "\n",
        "# Prints the final country facts table.\n",
        "print(df_country_facts)"
      ],
      "metadata": {
        "id": "tZtK7Oy-0b93",
        "outputId": "69bafd00-50dd-48d0-b783-d1bc045c17cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  country_code  mmpi_2023  reg_index  reg_cons_prot  reg_kyc_prop  \\\n",
            "0          KEN  Very high      88.00         100.00             0   \n",
            "1          TZA  Very high      87.16          83.33           100   \n",
            "2          UGA  Very high      88.33         100.00           100   \n",
            "\n",
            "   reg_entry_lim  reg_max_lim  reg_agent_el  num_providers  \\\n",
            "0            100          100           100              4   \n",
            "1            100          100           100              6   \n",
            "2            100          100           100              7   \n",
            "\n",
            "   earliest_launch_year  \n",
            "0                  2007  \n",
            "1                  2008  \n",
            "2                  2009  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting Survey Columns and Final Combination**"
      ],
      "metadata": {
        "id": "qpvYYE2Wz7SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists most useful columns from survey data.\n",
        "keep_survey = [\n",
        "    'country_code', 'female', 'age', 'educ', 'inc_q', 'urbanicity',\n",
        "    'account_mob', 'dig_account', 'anydigpayment', 'internet_use', 'wgt'\n",
        "]\n",
        "\n",
        "# Keeps only selected columns from combined survey data.\n",
        "df_survey_clean = df_micro[keep_survey].copy()\n",
        "\n",
        "# Joins survey data with country facts using country code.\n",
        "df_final = df_survey_clean.merge(df_country_facts, on='country_code', how='left')\n",
        "\n",
        "# Prints final table size to confirm.\n",
        "print(\"Final combined dataset shape:\", df_final.shape)\n",
        "\n",
        "# Prints first few rows of final table.\n",
        "print(\"First few rows:\\n\", df_final.head())\n",
        "\n",
        "# Prints percentage of missing values in each column.\n",
        "print(\"\\nMissing values (%):\\n\", df_final.isna().mean().sort_values(ascending=False).head(10))"
      ],
      "metadata": {
        "id": "WBoZKaubq9Bm",
        "outputId": "60cd3310-fa98-4648-bf94-b4ac60b1742d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final combined dataset shape: (3000, 20)\n",
            "First few rows:\n",
            "   country_code  female  age  educ  inc_q  urbanicity  account_mob  \\\n",
            "0          KEN       1   25   2.0      1           1            1   \n",
            "1          KEN       1   26   2.0      4           1            1   \n",
            "2          KEN       1   21   2.0      3           1            1   \n",
            "3          KEN       1   25   2.0      5           1            1   \n",
            "4          KEN       2   31   3.0      5           2            1   \n",
            "\n",
            "   dig_account  anydigpayment  internet_use       wgt  mmpi_2023  reg_index  \\\n",
            "0            1              1             1  0.723252  Very high       88.0   \n",
            "1            1              1             1  0.331405  Very high       88.0   \n",
            "2            1              1             1  1.071302  Very high       88.0   \n",
            "3            1              1             1  0.677005  Very high       88.0   \n",
            "4            1              1             1  0.457662  Very high       88.0   \n",
            "\n",
            "   reg_cons_prot  reg_kyc_prop  reg_entry_lim  reg_max_lim  reg_agent_el  \\\n",
            "0          100.0             0            100          100           100   \n",
            "1          100.0             0            100          100           100   \n",
            "2          100.0             0            100          100           100   \n",
            "3          100.0             0            100          100           100   \n",
            "4          100.0             0            100          100           100   \n",
            "\n",
            "   num_providers  earliest_launch_year  \n",
            "0              4                  2007  \n",
            "1              4                  2007  \n",
            "2              4                  2007  \n",
            "3              4                  2007  \n",
            "4              4                  2007  \n",
            "\n",
            "Missing values (%):\n",
            " educ             0.001\n",
            "country_code     0.000\n",
            "female           0.000\n",
            "age              0.000\n",
            "inc_q            0.000\n",
            "urbanicity       0.000\n",
            "account_mob      0.000\n",
            "dig_account      0.000\n",
            "anydigpayment    0.000\n",
            "internet_use     0.000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Final Dataset as CSV**"
      ],
      "metadata": {
        "id": "HLwJjGK7_-HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save the dataset as CSV in Colab's temporary storage\n",
        "df_final.to_csv('FinalCombine.csv', index=False)\n",
        "\n",
        "# 2. Install git if not already available (usually pre-installed in Colab)\n",
        "!apt-get update -qq && apt-get install -y git\n",
        "\n",
        "# 3. Configure git with your details (replace with your own email and username)\n",
        "!git config --global user.email \"your-email@example.com\"\n",
        "!git config --global user.name \"Your GitHub Username\"\n",
        "\n",
        "# 4. Clone your repository (replace with your actual repo URL)\n",
        "!git clone https://github.com/sitahlango-maker/Financial_Inclusion.git\n",
        "%cd Financial_Inclusion\n",
        "\n",
        "# 5. Move the CSV file to the desired folder inside the repo\n",
        "!mkdir -p \"Colab Notebooks/FinancialInclution\"\n",
        "!mv ../FinalCombine.csv \"Colab Notebooks/FinancialInclution/FinalCombine.csv\"\n",
        "\n",
        "# 6. Add, commit, and push the file to GitHub\n",
        "!git add \"Colab Notebooks/FinancialInclution/FinalCombine.csv\"\n",
        "!git commit -m \"Add FinalCombine.csv - combined Findex and country-level dataset\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "U_FJ1MZA_8vG",
        "outputId": "aee85353-2c91-48e0-c747-68dace591823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/content/drive/MyDrive/Colab Notebooks/FinancialInclution'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3757648289.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saves final combined dataset as CSV file in Drive folder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df_final.to_csv(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/FinancialInclution/FinalCombine.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/content/drive/MyDrive/Colab Notebooks/FinancialInclution'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Mobile Money Deployment Tracker\n",
        "df_preval = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/FinancialInclution/Mobile Money Prevalent Index-2020-23-Public(MMPI 2020-23).csv',\n",
        " )\n",
        "\n",
        "# Rename column for merging\n",
        "df_preval = df_preval[['Country', 'ISO3', 'Mobile Money Prevalence (2023)']]\n",
        "\n",
        "#--Remove rows without valid country code\n",
        "df_preval = df_preval.dropna(subset=['ISO3'])\n",
        "\n",
        "#--Select the columns to be used:\n",
        "df_preval = df_preval[['Country', 'ISO3', 'Mobile Money Prevalence (2023)']]\n",
        "\n",
        "#--Make the column names short and clear\n",
        "df_preval.columns = ['country_name', 'country_code', 'mmpi_2023']\n",
        "\n",
        "\n",
        "#--Keep only three countries (Kenya, Uganda and Tanzania)\n",
        "df_preval = df_preval[df_preval['country_code'].isin(['KEN', 'TZA', 'UGA'])]\n",
        "\n",
        "df_preval.columns.tolist()"
      ],
      "metadata": {
        "id": "EqBA13vxsnkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combining the four latter GSMA datasets With the Original Findex Dataset**"
      ],
      "metadata": {
        "id": "3dCVW1hAX6JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_country_facts = df_preval[['country_code', 'mmpi_2023']].copy()\n",
        "df_country_facts = df_country_facts.merge(df_reg[['country_code', 'reg_index', 'reg_cons_prot', 'reg_kyc_prop',\n",
        "                                                  'reg_entry_lim', 'reg_max_lim', 'reg_agent_el']],\n",
        "                                          on='country_code', how='left')\n",
        "df_deploy_info = df_providers.merge(df_oldest, on='country_code', how='left')\n",
        "df_country_facts = df_country_facts.merge(df_deploy_info, on='country_code', how='left')"
      ],
      "metadata": {
        "id": "I6JofyCebBWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing microdata (the three Findex survey files already combined in df_micro)\n",
        "# Adding country_code (just in case it's not updated properly)\n",
        "df_micro['country_code'] = df_micro['country'].map({\n",
        "    'Kenya': 'KEN',\n",
        "    'Tanzania': 'TZA',\n",
        "    'Uganda': 'UGA'\n",
        "})\n",
        "\n",
        "# Keep only the most useful survey columns\n",
        "keep_survey = [\n",
        "    'country_code', 'female', 'age', 'educ', 'inc_q', 'urbanicity',\n",
        "    'account_mob', 'dig_account', 'anydigpayment', 'internet_use', 'wgt'\n",
        "]\n",
        "df_survey_clean = df_micro[keep_survey].copy()\n",
        "\n",
        "# Building one small country facts table from the other five sources\n",
        "# Starting with prevalence dataset as base\n",
        "df_country_facts = df_preval[['country_code', 'mmpi_2023']].copy()\n",
        "\n",
        "# Adding regulatory scores\n",
        "df_country_facts = df_country_facts.merge(\n",
        "    df_reg[['country_code', 'reg_index', 'reg_cons_prot', 'reg_kyc_prop',\n",
        "            'reg_entry_lim', 'reg_max_lim', 'reg_agent_el']],\n",
        "    on='country_code',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Adding the number of providers and earliest launch year\n",
        "df_providers = df_deploy.groupby('Country ISO Code').size().reset_index(name='num_providers')\n",
        "df_earliest = df_deploy.groupby('Country ISO Code')['launch_year'].min().reset_index(name='earliest_launch')\n",
        "df_providers = df_providers.rename(columns={'Country ISO Code': 'country_code'})\n",
        "df_earliest  = df_earliest.rename(columns={'Country ISO Code': 'country_code'})\n",
        "\n",
        "df_deploy_info = df_providers.merge(df_earliest, on='country_code', how='left')\n",
        "df_country_facts = df_country_facts.merge(df_deploy_info, on='country_code', how='left')\n",
        "\n",
        "\n",
        "# Joining the country facts to every row of the survey data\n",
        "df_final = df_survey_clean.merge(\n",
        "    df_country_facts,\n",
        "    on='country_code',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Checking the result\n",
        "print(\"Final combined dataset shape:\", df_final.shape)\n",
        "print(\"First few rows:\\n\", df_final.head())\n",
        "print(\"\\nMissing values (%):\\n\", df_final.isna().mean().sort_values(ascending=False).head(10))\n",
        "\n",
        "# Saving the final file\n",
        "df_final.to_parquet(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/FinancialInclution/final_combined_data.parquet',\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "Wra4PCZrMfkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}